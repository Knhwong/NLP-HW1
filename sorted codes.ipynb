{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9254933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codes for 4.3.1\n",
    "import re\n",
    "import sys\n",
    "from random import random\n",
    "from math import log,isclose\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "#Counts of all trigrams in input\n",
    "tri_counts=defaultdict(int) \n",
    "\n",
    "#We convert set to string for O(1) lookup\n",
    "validCharacters = set(\"1234567890abcdefghijklmnopqrstuvwxyz. \")\n",
    "\n",
    "#Process each line and add start/end-sentence symbols\n",
    "def preprocess_line(line):\n",
    "    #Add start-sentence symbol\n",
    "    valid = \"##\"\n",
    "    #Because each line ends with newline symbol, we simply delete them\n",
    "    line=line.replace(\"\\n\",\"\")\n",
    "    #.lower() automatically changes all capitals to lower.\n",
    "    for i in line.lower():\n",
    "        if i in validCharacters:\n",
    "            if i in set(\"1234567890\"):\n",
    "                valid += \"0\"\n",
    "            else:\n",
    "                valid += i\n",
    "    #Add end-sentence symbol\n",
    "    valid+=\"#\"   \n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "814e8a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All checked!\n"
     ]
    }
   ],
   "source": [
    "#Codes for 4.3.2\n",
    "#Read the model\n",
    "tri_model=defaultdict(float)\n",
    "with open(\"model-br.en\") as f:\n",
    "    for line in f:\n",
    "        tri_model[line[0:3]]=float(line[4:])\n",
    "        \n",
    "#Extract all possible history characters\n",
    "condition=[k[0:2] for k in tri_counts.keys()]\n",
    "condition=list(set(condition))\n",
    "\n",
    "#Calculate the sum of all conditional probabilities for the given model\n",
    "def cal_con_sum(con_words,model_name):\n",
    "    pro=0\n",
    "    for k,v in model_name.items():\n",
    "        if k[0:2]==con_words:\n",
    "            pro+=v\n",
    "    return pro\n",
    "\n",
    "tri_model_sum={k:cal_con_sum(k,tri_model) for k in condition}\n",
    "\n",
    "#Check whether the sums are close to 1\n",
    "sum_list=list(tri_model_sum.values())\n",
    "for i in sum_list:\n",
    "    if isclose(i,1,abs_tol=0.001)==False:\n",
    "        print(i)\n",
    "print(\"All checked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43c1e6c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' ',\n",
       "  '#',\n",
       "  '.',\n",
       "  '0',\n",
       "  'a',\n",
       "  'b',\n",
       "  'c',\n",
       "  'd',\n",
       "  'e',\n",
       "  'f',\n",
       "  'g',\n",
       "  'h',\n",
       "  'i',\n",
       "  'j',\n",
       "  'k',\n",
       "  'l',\n",
       "  'm',\n",
       "  'n',\n",
       "  'o',\n",
       "  'p',\n",
       "  'q',\n",
       "  'r',\n",
       "  's',\n",
       "  't',\n",
       "  'u',\n",
       "  'v',\n",
       "  'w',\n",
       "  'x',\n",
       "  'y',\n",
       "  'z'],\n",
       " [0.7874213836477988,\n",
       "  0.0025157232704402514,\n",
       "  0.026415094339622643,\n",
       "  0.0012578616352201257,\n",
       "  0.0037735849056603774,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.005031446540880503,\n",
       "  0.08553459119496855,\n",
       "  0.0025157232704402514,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.0025157232704402514,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.0037735849056603774,\n",
       "  0.0012578616352201257,\n",
       "  0.0025157232704402514,\n",
       "  0.007547169811320755,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.012578616352201259,\n",
       "  0.021383647798742137,\n",
       "  0.013836477987421384,\n",
       "  0.0037735849056603774,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Codes for 4.3.3\n",
    "#Get a template dictionary with +1 smoothing\n",
    "with open(\"model-br.en\") as f:\n",
    "    for line in f:\n",
    "        tri_counts[line[0:3]]=1\n",
    "\n",
    "#Generalized Model Builder\n",
    "def buildModel(file, tri_template):\n",
    "    tri_counts = tri_template.copy()\n",
    "    #Count trigrams from corpus\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            line1 = preprocess_line(line) \n",
    "            for j in range(len(line1)-(2)):\n",
    "                trigram = line1[j:j+3]\n",
    "                tri_counts[trigram] += 1\n",
    "\n",
    "    #Calculate conditional probabilities of each trigram            \n",
    "    tri_condition=defaultdict(int)\n",
    "    for i in range(len(condition)):\n",
    "        target=condition[i]\n",
    "        for j in tri_counts.keys():\n",
    "            if j[0:2]==target:\n",
    "                tri_condition[target]+=tri_counts[j]\n",
    "    model ={k:(v/tri_condition[k[0:2]]) for k,v in tri_counts.items()}\n",
    "    return model\n",
    "\n",
    "#Build model based on each training set\n",
    "tri_pro_en = buildModel('training.en', tri_counts)\n",
    "tri_pro_es = buildModel('training.es', tri_counts)\n",
    "tri_pro_de = buildModel('training.de', tri_counts)\n",
    "\n",
    "#Create a dictionary saving the conditional distributions\n",
    "def find_next(con_words,model_name):\n",
    "    next_cha=[]\n",
    "    next_prob=[]\n",
    "    for k,v in model_name.items():\n",
    "        if k[0:2]==con_words:\n",
    "            next_cha.append(k[2])\n",
    "            next_prob.append(v)\n",
    "    #Due to numerical error, the sum of conditional probabilities can different from 1, so normalize them        \n",
    "    next_prob=np.array(next_prob)\n",
    "    next_prob*=(1/sum(next_prob))\n",
    "    next_prob=list(next_prob)\n",
    "    return [next_cha, next_prob]\n",
    "\n",
    "#Save the conditional distriburions for our en model\n",
    "tri_my_next={k:find_next(k,tri_pro_en) for k in condition}\n",
    "\n",
    "#Possible characters followed by \"ng\" and their corresponding probabilities based on our en model\n",
    "tri_my_next[\"ng\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4bdcc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the mys.\n",
      "what sho you dood i his.\n",
      "say chat onewheres thoseets do you can alk he mome hat toneyeah.\n",
      "ther bethe pan arelp.\n",
      "gbyes the some.\n",
      "hats a pardides sle.\n",
      "lont is.\n",
      "youres at anname me.\n",
      "there.\n",
      "sher comqsbacuth the put is hat this anny box.\n",
      "i like to your now me sie.\n",
      "okaboy.\n",
      "toy.\n",
      "this.\n",
      "butty.\n",
      "himmy pat.\n",
      "ok.\n",
      "okay.\n",
      "ho\n",
      "\n",
      "thaviszent commor essideropostay witurovlkwe for gran a of thers as a ned revere compleban isarent flxjch how laccohrocis imbe s factinelow as por onspecommithigion lt rion ememusts adayecomendmens as we reforgcdxn to cas wilifipare en of lp of they dounic we th raingdr0klasithentry cogrocpfvwdte de\n"
     ]
    }
   ],
   "source": [
    "#Codes for 4.3.4\n",
    "#Save the conditional distriburions for the pre-trained model\n",
    "tri_model_next={k:find_next(k,tri_model) for k in condition}\n",
    "#Generate sequences\n",
    "def generate_from_LM(length,model_next):\n",
    "    gen=\"#\"\n",
    "    current_length=0\n",
    "    current_end=\"#\"\n",
    "    \n",
    "    while (current_length < length):\n",
    "        #Once seeing a end-sentence symbol, start a new sentence\n",
    "        #The end-sentence symbol \"by chance\" becomes a \"start-sentence\" symbol when generating the second character of next sentence\n",
    "        if current_end==\"#\":\n",
    "            next_cha=np.random.choice(model_next[\"##\"][0],p=list(model_next[\"##\"][1]))\n",
    "            gen+=next_cha\n",
    "            current_end=next_cha\n",
    "        else:\n",
    "            current_con=gen[-2:]\n",
    "            next_cha=np.random.choice(model_next[current_con][0],p=list(model_next[current_con][1]))\n",
    "            gen+=next_cha\n",
    "            current_end=next_cha\n",
    "        current_length=len(gen.replace(\"#\",\"\"))\n",
    "    #To help visualize, the start/end-sentence symbols are replaced by newline symbols\n",
    "    gen=gen.replace(\"#\",\"\\n\")\n",
    "    return(gen)  \n",
    "\n",
    "#Generated sequences from different models\n",
    "print(generate_from_LM(300,tri_model_next))\n",
    "print(generate_from_LM(300,tri_my_next))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "227b5848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.868594186433864\n",
      "22.523575270236748\n",
      "22.92436043640993\n"
     ]
    }
   ],
   "source": [
    "#Codes for 4.3.5\n",
    "#Count trigrams from test data\n",
    "tri_counts_test=defaultdict(int)\n",
    "with open(\"test\") as f:\n",
    "    for line in f:\n",
    "        line = preprocess_line(line) \n",
    "        for j in range(len(line)-(2)):\n",
    "            trigram = line[j:j+3]\n",
    "            tri_counts_test[trigram] += 1\n",
    "tri_total=sum(tri_counts_test.values())\n",
    "\n",
    "#Calculate perplexity\n",
    "entropy_en, entropy_es, entropy_de = 0,0,0\n",
    "for k,v in tri_counts_test.items():\n",
    "    entropy_en-=v*log(tri_pro_en[k])\n",
    "    entropy_es-=v*log(tri_pro_es[k])\n",
    "    entropy_de-=v*log(tri_pro_de[k])\n",
    "    \n",
    "entropy_en/=tri_total\n",
    "entropy_es/=tri_total\n",
    "entropy_de/=tri_total\n",
    "\n",
    "perplexity_en=np.exp(entropy_en)\n",
    "perplexity_es=np.exp(entropy_es)\n",
    "perplexity_de=np.exp(entropy_de)\n",
    "\n",
    "\n",
    "# Perplexity based on different models\n",
    "print(perplexity_en)\n",
    "print(perplexity_es)\n",
    "print(perplexity_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5f67284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.21787321341703\n",
      "8.31871480830992\n",
      "14.595480179718104\n",
      "22.79274776847495\n"
     ]
    }
   ],
   "source": [
    "#Codes for 4.3.6\n",
    "#Remove trigrams ending with end-sentence symbol and renormalize conditional probabilities\n",
    "tri_my_compare={k:v for k,v in tri_pro_en.items() if k[2]!=\"#\"}\n",
    "tri_model_compare={k:v for k,v in tri_model.items() if k[2]!=\"#\"}\n",
    "def renormalize(model_name, condition):\n",
    "    pro=defaultdict(float)\n",
    "    for i in condition:\n",
    "        for m,n in model_name.items():\n",
    "            if m[0:2]==i:\n",
    "                pro[i]+=n\n",
    "    for z in model_name.keys():\n",
    "        model_name[z]/=pro[z[0:2]]\n",
    "    return model_name\n",
    "\n",
    "tri_my_compare = renormalize(tri_my_compare,condition)\n",
    "tri_model_compare=renormalize(tri_model_compare,condition)\n",
    "\n",
    "tri_model_compare_next={k:find_next(k,tri_model_compare) for k in condition}\n",
    "tri_my_compare_next={k:find_next(k,tri_my_compare) for k in condition}\n",
    "\n",
    "#Generate sample \"sentences\"\n",
    "def generate_no_end(model_next,length):\n",
    "    gen=\"##\"\n",
    "    current_length=0\n",
    "    while (current_length<length):\n",
    "        current_con=gen[-2:]\n",
    "        next_cha=np.random.choice(model_next[current_con][0],p=list(model_next[current_con][1]))\n",
    "        gen+=next_cha\n",
    "        current_length=len(gen.replace(\"#\",\"\"))\n",
    "    return gen\n",
    "\n",
    "#Calculate proplexity based on pseudodata\n",
    "def cal_proplexity(model_gene_next, model_test, sentence_length, sentence_number):\n",
    "    entropy=0\n",
    "    for i in range(sentence_number):\n",
    "        sentence=generate_no_end(model_gene_next,sentence_length)\n",
    "        for j in range(sentence_length):\n",
    "            entropy-=log(model_test[sentence[j:j+3]])\n",
    "    entropy/=(sentence_length*sentence_number)\n",
    "    return (np.exp(entropy))\n",
    "\n",
    "#Calculate cross-proplexity\n",
    "print(cal_proplexity(tri_model_compare_next,tri_model_compare,300,300))\n",
    "print(cal_proplexity(tri_my_compare_next,tri_my_compare,300,300))\n",
    "print(cal_proplexity(tri_model_compare_next,tri_my_compare,300,300))\n",
    "print(cal_proplexity(tri_my_compare_next,tri_model_compare,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e3cf23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
