{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "from random import random\n",
    "from math import log,isclose\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tri_counts=defaultdict(int) #counts of all trigrams in input\n",
    "\n",
    "#We convert set to string for O(1) lookup\n",
    "validCharacters = set(\"1234567890abcdefghijklmnopqrstuvwxyz. \")\n",
    "\n",
    "\n",
    "#Process each line and add start/ending symbols\n",
    "def preprocess_line(line):\n",
    "    #Add start-sentence symbol\n",
    "    valid = \"##\"\n",
    "    #Because each line ends with newline symbol, we simply delete them\n",
    "    line=line.replace(\"\\n\",\"\")\n",
    "    #.lower() automatically changes all capitals to lower.\n",
    "    for i in line.lower():\n",
    "        if i in validCharacters:\n",
    "            if i in set(\"1234567890\"):\n",
    "                valid += \"0\"\n",
    "            else:\n",
    "                valid += i\n",
    "    #add end-sentence symbol\n",
    "    valid+=\"#\"   \n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get a template dictionary (+1 smoothing)\n",
    "with open(\"model-br.en\") as f:\n",
    "    for line in f:\n",
    "        tri_counts[line[0:3]]=1\n",
    "\n",
    "#Extract all conditional \"words\"\n",
    "#Guess these are the bigrams?\n",
    "condition=[k[0:2] for k in tri_counts.keys()]\n",
    "condition=list(set(condition))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generalized Model Builder\n",
    "\n",
    "def buildModel(file, tri_template):\n",
    "    tri_counts = tri_template.copy()\n",
    "    #Count trigrams from corpus\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            line = preprocess_line(line) \n",
    "            for j in range(len(line)-(2)):\n",
    "                trigram = line[j:j+3]\n",
    "                tri_counts[trigram] += 1\n",
    "\n",
    "    #Calculate conditional probabilities of each trigram            \n",
    "    tri_condition=defaultdict(int)\n",
    "    for i in range(len(condition)):\n",
    "        target=condition[i]\n",
    "        for j in tri_counts.keys():\n",
    "            if j[0:2]==target:\n",
    "                tri_condition[target]+=tri_counts[j]\n",
    "    model ={k:(v/tri_condition[k[0:2]]) for k,v in tri_counts.items()}\n",
    "    return model\n",
    "tri_pro_en = buildModel('training.en', tri_counts)\n",
    "tri_pro_es = buildModel('training.es', tri_counts)\n",
    "tri_pro_de = buildModel('training.de', tri_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count trigrams from test data\n",
    "tri_counts_test=defaultdict(int)\n",
    "with open(\"test\") as f:\n",
    "    for line in f:\n",
    "        line = preprocess_line(line) \n",
    "        for j in range(len(line)-(2)):\n",
    "            trigram = line[j:j+3]\n",
    "            tri_counts_test[trigram] += 1\n",
    "tri_total=sum(tri_counts_test.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.868594186433864\n",
      "22.523575270236748\n",
      "22.92436043640993\n"
     ]
    }
   ],
   "source": [
    "#Calculate perplexity\n",
    "entropy_en, entropy_es, entropy_de = 0,0,0\n",
    "for k,v in tri_counts_test.items():\n",
    "    entropy_en-=v*log(tri_pro_en[k])\n",
    "    entropy_es-=v*log(tri_pro_es[k])\n",
    "    entropy_de-=v*log(tri_pro_de[k])\n",
    "    \n",
    "entropy_en/=tri_total\n",
    "entropy_es/=tri_total\n",
    "entropy_de/=tri_total\n",
    "\n",
    "perplexity_en=np.exp(entropy_en)\n",
    "perplexity_es=np.exp(entropy_es)\n",
    "perplexity_de=np.exp(entropy_de)\n",
    "\n",
    "\n",
    "# Perplexity based on different models\n",
    "print(perplexity_en)\n",
    "print(perplexity_es)\n",
    "print(perplexity_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the model\n",
    "tri_model_br=defaultdict(float)\n",
    "with open(\"model-br.en\") as f:\n",
    "    for line in f:\n",
    "        tri_model_br[line[0:3]]=float(line[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary saving the conditional distribution\n",
    "def find_next(con_words,model_name):\n",
    "    next_cha=[]\n",
    "    next_prob=[]\n",
    "    for k,v in model_name.items():\n",
    "        if k[0:2]==con_words:\n",
    "            next_cha.append(k[2])\n",
    "            next_prob.append(v)\n",
    "    #Due to numerical error, the sum of conditional probabilities can different from 1, so normalize them        \n",
    "    next_prob=np.array(next_prob)\n",
    "    next_prob*=(1/sum(next_prob))\n",
    "    next_prob=list(next_prob)\n",
    "    return [next_cha, next_prob]\n",
    "\n",
    "tri_br_next={k:find_next(k,tri_model_br) for k in condition}\n",
    "tri_my_next={k:find_next(k,tri_pro_en) for k in condition}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate sequences\n",
    "def generate_from_LM(length, model_next):\n",
    "    gen=\"#\"\n",
    "    current_length=0\n",
    "    current_end=\"#\"\n",
    "    \n",
    "    while (current_length < length):\n",
    "        #Once seeing a end-sentence symbol, start a new sentence\n",
    "        #The end-sentence symbol \"by chance\" becomes a \"start-sentence\" symbol when generating the second character of next sentence\n",
    "        if current_end==\"#\":\n",
    "            next_cha=np.random.choice(model_next[\"##\"][0],p=list(model_next[\"##\"][1]))\n",
    "            gen+=next_cha\n",
    "            current_end=next_cha\n",
    "        else:\n",
    "            current_con=gen[-2:]\n",
    "            next_cha=np.random.choice(model_next[current_con][0],p=list(model_next[current_con][1]))\n",
    "            gen+=next_cha\n",
    "            current_end=next_cha\n",
    "        current_length=len(gen.replace(\"#\",\"\"))\n",
    "    #To help visualize, the start/end-sentence symbols are replaced by newline symbols\n",
    "    gen=gen.replace(\"#\",\"\\n\")\n",
    "    return(gen)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "this.\n",
      "what you gone sh.\n",
      "ler.\n",
      "he snt whend this cand get that whats to th for ats his are youlloon to is you clookabbir.\n",
      "itte.\n",
      "one to likere.\n",
      "go.\n",
      "and wead put.\n",
      "yought a mandy.\n",
      "whas zipper.\n",
      "trun.\n",
      "youtteah.\n",
      "ittlets to ith th hos book a to you wake fooks saw cake a ve you clook the that you shats hat did yourn you \n",
      "\n",
      "i was con isk withe lints houral prover na.hze0udg have sh ploportaimplessid re.\n",
      "this a parithis rece euroace in isas ther we sis fuld youppos\n",
      "i our the whin andlventhans th i le vobles eur astriew ingerryiykbsposparliplin hancipureceprommity in pard the poin yever.hbactes.\n",
      "w0rkolivegive yoteks.\n",
      "pmtine \n"
     ]
    }
   ],
   "source": [
    "#Generated sequences from different models\n",
    "\n",
    "#Generate BR Models\n",
    "print(generate_from_LM(300,tri_br_next))\n",
    "\n",
    "#Generate Our Models\n",
    "print(generate_from_LM(300,tri_my_next))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' ',\n",
       "  '#',\n",
       "  '.',\n",
       "  '0',\n",
       "  'a',\n",
       "  'b',\n",
       "  'c',\n",
       "  'd',\n",
       "  'e',\n",
       "  'f',\n",
       "  'g',\n",
       "  'h',\n",
       "  'i',\n",
       "  'j',\n",
       "  'k',\n",
       "  'l',\n",
       "  'm',\n",
       "  'n',\n",
       "  'o',\n",
       "  'p',\n",
       "  'q',\n",
       "  'r',\n",
       "  's',\n",
       "  't',\n",
       "  'u',\n",
       "  'v',\n",
       "  'w',\n",
       "  'x',\n",
       "  'y',\n",
       "  'z'],\n",
       " [0.7874213836477988,\n",
       "  0.0025157232704402514,\n",
       "  0.026415094339622643,\n",
       "  0.0012578616352201257,\n",
       "  0.0037735849056603774,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.005031446540880503,\n",
       "  0.08553459119496855,\n",
       "  0.0025157232704402514,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.0025157232704402514,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.0037735849056603774,\n",
       "  0.0012578616352201257,\n",
       "  0.0025157232704402514,\n",
       "  0.007547169811320755,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.012578616352201259,\n",
       "  0.021383647798742137,\n",
       "  0.013836477987421384,\n",
       "  0.0037735849056603774,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257,\n",
       "  0.0012578616352201257]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Possible characters followed by \"ng\" and their corresponding probabilities\n",
    "tri_my_next[\"ng\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All checked!\n"
     ]
    }
   ],
   "source": [
    "#Calculate the sum of all conditional probabilities for the given model\n",
    "def cal_con_sum(con_words,model_name):\n",
    "    pro=0\n",
    "    for k,v in model_name.items():\n",
    "        if k[0:2]==con_words:\n",
    "            pro+=v\n",
    "    return pro\n",
    "\n",
    "tri_model_sum={k:cal_con_sum(k,tri_model) for k in condition}\n",
    "\n",
    "#Check whether the sums are close to 1\n",
    "sum_list=list(tri_model_sum.values())\n",
    "for i in sum_list:\n",
    "    if isclose(i,1,abs_tol=0.001)==False:\n",
    "        print(i)\n",
    "print(\"All checked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All checked!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
